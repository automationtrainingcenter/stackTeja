spring.application.name=stackSimplify

# Ollama Configuration
spring.ai.ollama.base-url=http://localhost:11434
spring.ai.ollama.chat.model=phi4-mini
spring.ai.ollama.chat.options.temperature=0.2
spring.ai.ollama.chat.options.num_predict=1024

# Custom AI Provider Properties
# Current active provider is Ollama with phi4-mini model
app.ai.ollama.enabled=true
app.ai.ollama.defaultModel=phi4-mini

# OpenAI configuration (disabled by default)
app.ai.openai.enabled=false
app.ai.openai.apiKey=
app.ai.openai.defaultModel=gpt-3.5-turbo

# Claude configuration (disabled by default)
app.ai.claude.enabled=false
app.ai.claude.apiKey=
app.ai.claude.defaultModel=claude-3-haiku
